# Robotics Final Project

## File Structure & Descriptions
```
---------------
+ = Python file
> = npy file
* = URDF file

For more details, see comments in code
---------------
+ config.py
    - Defines and initializes global variables, robot sensors, and robot state
+ controls.py
    - Contains the code for the manual controller and autonomous controller for driving the robot around the world
+ goal_object_detection.py
    - Uses openCV color detection to inform if a goal object is present in the frame.
+ grocery_shopper.py
    - This file is the main thread of execution and is the file that the Tiago Robot has set to the main controller. Based on the robot's state, the file calls upon other files to change the robot behavior. The main loop resides here.
+ helpers.py
    - Contains general functions that are used throughout the program.
+ manipulator.py
    - IK and manual manipulator combined. This gives user the control to adjust joints of the manipulator as well as providing functionality for the user to choose to use inverse kinematics to navigate the arm to positions.
+ mapping.py
    - Functionality for obtaining lidar readings and robot position and displaying them on a map. When mapping, this file also saves the position and lidar sensor information to a probability map, which is later used for path planning.
+ planner.py
    - Uses a navigation algorithm and the convolved map from the initial mapping phase to construct a path composed of waypoints. 
+ transformation.py
    - Contains functions for translating between map, world, and display coordinate systems.
+ trilateration.py
    - Uses cones and additional lidar to trilaterate position based on artificial noisy GPS measurement
> checkpoints.npy
    - Contains a list of checkpoints that were generated in the mapping step. Each checkpoint either represents a user defined stopping point or a goal object detection.
> map.npy
    - Probability map of lidar measurments for obstacles.
> path.npy
    - List of waypoints inbetween checkpoints and current position that is generated by navigation algorithm.
* tiago_urdf.urdf
    - Generated urdf file. Initially the given urdf file was used, but there were some parsing issues when using IKpy.
```
## Changes to .wbt File
* Additional Sensors
    * onboard_lidar_1
        * this is used for better mapping objects in the facility. Essentially, we just moved the existing lidar up to the top of the robot to avoid detecting the floor in the lidar obstacle measurements
    * slam_lidar_0
        * lidar for front 180 FOV of robot to detect cones in order for trilateration
    * slam_lidar_1
        * lidar for rear 180 FOV of robot to detect cones for trilateration algorithm

* Additional Objects
    * 18 Cone objects
        * Used as "landmark" objects or base stations in trilateration algorithm. Each has set position over all obstacles in the world so that robot has full sensing ability for these without having to take into consideration FOV blocking by obstacles.

## Resources Used

https://github.com/lukicdarkoo/webots-example-visual-tracking/blob/master/controllers/visual_tracker/visual_tracker.py

    - For color detection

https://gist.github.com/ItsMichal/4a8fcb330d04f2ccba582286344dd9a7

    - For manipulator IK

https://en.wikipedia.org/wiki/A*_search_algorithm

    - Route planning

https://www.alanzucconi.com/2017/03/13/positioning-and-trilateration/

    - Trilateration 

## Video Link
